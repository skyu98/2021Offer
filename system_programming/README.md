[toc]
# 进程
* **程序**，是指存放在磁盘上的编译好的二进制文件，**不占用系统资源**(cpu、内存、打开的文件、设备、锁）

* **当程序运行起来，操作系统则会为该程序分配资源，形成进程。**
* 因此，**进程是操作系统分配资源的最小单位**


## 1.PCB进程控制块
进程在Linux系统中可以具象化为```PCB进程控制块(Process Control Block)```，其是一个结构体，里面维护了一个进程的相关信息。
|PCB项|内容|
|:--:|:--:|
|进程ID|系统中每个进程有唯一的id ,在C中用pid_t表示|
|进程状态|初始、就绪、运行、挂起、终止|
|上下文|进程切换时需要保存和恢复的一些CPU寄存器|
|VMA|描述虚拟地址空间的信息|
|文件描述符表|包含很多指向file结构体的指针|

## 2.进程的内存空间分布
当进程被创建时，以32位系统为例，操作系统会为其分配$4G(2^{32})$的虚拟地址空间：
![avatar](./imgs/Memory.png)

|区域名称|内容|
|:--:|:--:|
|内核区|系统中所有进程共享（映射到同一片物理内存）|
|环境变量及命令行参数|当前的环境变量以及```char argv[]```|
|`.stack`|局部变量、函数栈；由栈指针维护|
|`.memory_mapping`|共享的动态库、内存映射区域|
|`.heap`(created by `malloc()`)|动态申请的内存区域|
|`.bss`|未初始化的全局变量（值为0）|
|`.data`|已初始化的全局变量|
|.`text`、 `.rodata` 、`.init`|代码段，二进制机器指令;只读数据;初始化代码|

每个进程都有如上的一份虚拟地址空间：
* 1. **并不代表一个进程真正地占有了$4G$内存空间**
* 2. 寻址的时候需要由```MMU(Memory Manage Unit)内存管理单元```，将虚拟地址翻译为物理地址。

## 3.虚拟地址寻址的大概过程(三级页表为例)
虚拟地址被分为以下三部分：
|页目录偏移（10bit)|页表偏移（10bit）|物理页偏移（12bit）|
|--|--|--|
当CPU需要访问存放在虚拟地址```VA(Virtual Address)```的数据时， MMU会:
* 1. 访问保存在PTBR寄存器的页目录基址（类似数组开头）：
    页目录基址 + 页目录偏移 = 对应页表
* 2. 页表基址 + 页表偏移 = 对应页表项（标志位 + 物理页基址）
* 3. 若物理页**尚未分配，内核先在磁盘上分配对应大小的物理页**；
    若物理页**已分配尚未缓存，内核采用换出换入算法将victim page从物理内存中换出**；
    （-----以上会引发**缺页中断**----------）
    若物理页已缓存，**物理页基址 + 物理页偏移 = 数据地址（命中）**
* 4. 返回数据给CPU

## 4.进程的特点
* 1. 分配资源的最小单位（CPU，三级页表）
* 2. 进程宏观并行，微观串行（时间片）；切换（创建、销毁）时开销大
* 3. 进程间相互独立，互不影响（虚拟地址分隔/三级页表不同）
* 4. 进程间通信（```Inter—Process Communication```)复杂
* 5. 多机扩展方便

---
# 线程
考虑当某个进程有A、B两个任务，其中A需要等待某种资源（IO等）；
**当所需资源没准备好时，该进程就会挂起———然而执行B任务并不需要该资源**；
所以我们需要一个**粒度更小的、能够共享已有资源的单位———线程**

## 1.独立的PCB + 共享的三级页表
Linux中，线程的本质也是进程（```light weight process```）；
这意味着**每个线程也会有自己的PCB和三级页表**
* 1.每个线程的**PCB是独立的**；因此每个线程可以单独区分开来(**内核栈：线程ID/处理器现场、栈指针**)；
* 2.**三级页表是共享的**；因此线程间可以共享资源，因为其虚拟地址空间（```.text/.data/.bss/.heap/.mmap```）相同；
* 3.线程**独享栈和寄存器**：**在线程被创建时，内核会使用mmap()在.mmap段给新线程创建其独有的栈空间**；开辟的线程栈空间一般上限为8M（线程是轻量级进程），`ulimit -s xxx`修改。

## 2.线程的优缺点
* 优点：
    * 1.提高了程序的并发性（各线程利用共享资源执行自己的任务）
    * 2.创建、切换、销毁开销小（不同额外创建虚拟地址空间）
    * 3.线程间通信简单（共享虚拟地址空间）

* 缺点：
    * 1.调试较为复杂（对应优点1）
    * 2.**在使用共享资源时必须考虑同步！（锁、条件变量、volatile + 互斥）**
---

# IPC
## 1.pipe - 匿名管道
原理：管道实为内核使用环形队列机制，借助**内核缓冲区**实现。
```cpp
int fd[2]; // 0:读端 1：写端
pipe(fd);
```
优点：简单
缺点：
* ① 只能在有血缘关系的进程间使用(他们的文件描述符表相同)
* ② 管道中数据不可反复读取。一旦读走，管道中不再存在
* ③ 采用半双工通信方式，数据只能在单方向上流动

## 2.fifo - 命名管道
FIFO 是 Linux 基础文件类型中的一种 。
但FIFO 文件在磁盘上没有数据块，仅仅用来标识**内核中一条通道**。
各进程可以打开这个文件进行 read /write 实际上是在读写内核通道 ，这样就实现了进程间通信。
```cpp
mkfifo filename// 命令行创建
int mkfifo(const char *path, mode_t mode); // 函数创建
```
优点：
* ① 简单
* ② 可在无血缘关系的进程间使用

缺点：
* ① 管道中数据不可反复读取。一旦读走，管道中不再存在
* ② 采用半双工通信方式，数据只能在单方向上流动

## 3.mmap - 共享存储映射
存储映射I/O（Memory mapped I/O） 使一个磁盘文件与存储空间中的一个缓冲区相映射。
于是当从缓冲区中取数据就相当于读文件中的相应字节；将数据存入缓冲区则类似将相应的字节写入文件。
这样，就可在不适用read和write函数的情况下，使用地址（指针）完成I/O操作。

![avatar](./imgs/mmap.jpg)

```cpp
void* mmap(void *addr, size_t len, int prot, int flags, int fd, off_t offset);
// 返回值为void*，因为内核不知道该段内存将要存放的数据类型
```
优点：
* ① 通过指针，操作多种多样
* ② 可在无血缘关系的进程间使用

缺点：
* ① 出错概率高
* ② 小文件mmap可能造成内存浪费

特点：
* 1. 创建映射区的过程中，隐含着一次对映射文件的读操作。
* 2. 当```MAP_SHARED```时，要求：映射区的权限应小于等于文件打开的权限出于对映射区的保护。而```MAP_PRIVATE```则无所谓， 因为```mmap```中的权限是对内存的限制。
* 3. 映射区的释放与文件关闭无关。只要映射建立成功，文件可以立即关闭。
* 4. 特别注意，当映射文件大小为 0 时，不能创建映射区。**所以：用于映射的文件必须要有实际大小！！**
* 5. **```munmap```传入的地址一定是```mmap```的返回地址。坚决杜绝指针++操作。**
* 6. 文件偏移量必须为```4K```的整数倍
* 7. ```mmap```创建映射区出错概率非常高 一定要检查返回值，确保映射区建立成功再进行后续操作。

---

# 线程间同步

## 1.同步
“同步”的目的，是**避免数据混乱，解决与时间有关的错误**。实际上，不仅线程间需要同步，进程间、信号间等等都需要同步机制。
因此， **所有“多个控制流共同操作一个共享资源” 的情况**，都需要同步。

## 2.线程同步

线程同步，指一个线程发出某一功能调用时，在没有得到结果之前，该调用不返回。同时其它线程为保证数据一致性，不能调用该功能。

### 2.1 互斥量Mutex
```cpp
#include <mutex>
std::mutex mutex; // 该锁应全局共享
int global_var = 100; // 共享资源

void threadFunc() {
    // .......
    {
        // 加锁。若不成功则阻塞等待
        std::lock_guard<std::mutex> lock(mutex_); 
        // 获得锁，访问共享资源;其他线程无法取得锁
        global_var = 200;
    }
    // lock_guard析构，解锁;其他线程可以取得锁
    // .......
}
```
* 1. 每个线程在**对资源操作前都尝试先加锁**，成功加锁才能操作，**操作结束解锁**
* 2. 同一时刻，只能有一个线程持有该锁
* 3. 互斥锁实质上是操作系统提供的一把“建议锁”，**并没有强制限定**
* 4. **锁的粒度要尽量小**，在访问完成后立即解锁，减少等待时间

#### 死锁
四个条件：
1. 互斥原则
2. 请求并保持
3. 已有不剥夺
4. 循环等待


### 2.2 读写锁rwlock
考虑某种**读多写少**的场景，如余额查询；某个线程在读共享数据的时候其他线程不能读，这显然是不合理的；原因是**没有区分访问的类型**。
更好的解决方案是：**写独占，读共享**。
```cpp
// 创建一把读写锁
pthread_rwlock_t rwlock;

// 初始化读写锁
// attr表读写锁属性，通常使用默认属性,传NULL即可
int pthread_rwlock_init(pthread_rwlock_t *lock, const pthread_rwlockattr_t *attr);

// 写加锁
pthread_rwlock_wrlock(&rwlock)；

// 读加锁
pthread_rwlock_rdlock(&rwlock);

// 解锁
pthread_rwlock_unlock(&rwlock);

```
#### 读写锁特性：
* 1. “写模式加锁”时，**解锁前，所有对该锁加锁的线程都会被阻塞**。
* 2. “读模式加锁”时，**如果线程以读模式对其加锁会成功；以写模式加锁会阻塞。**
* 3. 读锁、写锁并行阻塞，**写锁优先级高**

### 2.3 条件变量
**条件变量不是锁**，只是提供一个场所，让所有线程在此交汇；但是其本质也是对共享资源的访问，所以要搭配一把锁使用。

#### 生产者-消费者模型
既然线程是在等待条件满足，那么很容易想到**生产者-消费者模型**——生产线程产出一个产品后，则通知消费线程条件满足（**队列不为空**），消费线程则被唤醒，进行消费。

```cpp
// 显然，条件变量和锁都应该是全局共享
std::mutex mutex;
std::condition_variable cv;
std::queue<T> queue; // 共享资源

void consumer()
{
    // ......
    std::unique_lock<std::mutex> lock(mutex);
    while(/* 条件不满足 */)
    {
        // 解锁，阻塞等待条件满足
        cv.wait(lock);
        // 当条件满足，该阻塞线程被唤醒
        // 再次检查是否满足条件
    }
    // 条件满足，获得锁，进行访问
    // ......
}

void producer()
{
    // ......
    // 生产并放入队列
    queue.emplace_back(T);
    // 唤醒一个阻塞的消费线程
    cv.notify();
    // ......
}
```
#### 优点：
**相较于mutex而言，条件变量可以减少竞争。**
如直接使用mutex，**如果临界区中没有数据，消费者之间竞争mutex是无意义的**。有了条件变量机制以后，只有生产者完成生产，才会引起消费者之间的竞争。提高了程序效率。

#### 注意点：
* 1.多个消费者线程存在时，线程被唤醒，可能其它线程已经消费，条件此时并不满足，即**虚假唤醒**；应该使用```while()```来进行条件判断。
* 2.在代码块结束后将释放锁；**妥善考虑代码块结束的位置**。
* 3.可以通过生产特殊的商品来控制消费者线程退出。
* 4.当封装成```BoundedBlockingQueue```对象，在**析构时一定要唤醒所有线程并通过标志位指导其退出**，才能避免一直阻塞不能对其进行回收。

### 2.4 信号量
信号量的概念错综复杂，这里只讲自己的想法：

* 1.```Semaphore```可以初始化为任何非负整数
* 2.```Semaphore```值大于0时，线程**获取资源**，并且```--Semaphore```；等于0时，代表已经没有资源，线程挂起等待
* 3.当线程使用完资源之后，```++Semaphore```。

* 4.**资源可以是访问临界区的权限（取完后不能再进入），也可以是共享资源的个数（取完后不能再取出）**

根据上面的分析，信号量有下列用途：
* 1.初始化为1：此时相当于互斥锁
* 2.初始化为非负整数N：代表有N个线程可以访问临界区/有N个共享资源可以取用

更多的细节参考：
https://zhuanlan.zhihu.com/p/112173283

---

# 五种I/O模型
I/O是指我们需要从磁盘、网络、内存等容器中读取或写入数据。（下面以`read()`读取网络数据为例）
## 1.阻塞IO
这是一种最普通的IO：我们调用read()之后，**如果没有数据准备好，我们将会阻塞等待**——本线程会**挂起直到有数据到来**。

* 显然这样的效率并不高，因为如果长时间无数据到来，我们的线程就一直处于空闲状态。

## 2.非阻塞IO
我们可以在创建fd时就指定其为`Non-blocking`，也可以在创建之后通过fctrl()将其设置为非阻塞；
但都只为了同一个效果：**在数据未准备好时，直接返回-1，并且以错误码形式来表示读取的结果**（通常为`EAGAIN/EWOULDBLOCK`）

* 这样我们无需阻塞等待数据到来；但显然我们更不希望错过这个数据。因此，在这种模型中我们需要以**忙轮询**的方式，
不断查看数据是否到来。
* 我们可**以在两次轮询之间处理一些其他的任务**，但这样由于可能**不能及时读取数据而造成吞吐量下降**。

***如果只使用上述两种简单模型，那么对于多个连接我们就需要创建多个进程/线程来进行处理***

## 3.IO多路复用（⭐️）
能不能在一个线程当中，方便地去轮询多个fd呢？
Unix当中提供了`select`, `poll`, `epoll`三个函数。（三者具体区别见下一部分总结）
* 它们**通过把多个I/O的阻塞复用到同一个函数的阻塞上，同时监控多个fd的状态，并且在有可写/可读事件到来时告知用户**，使得用户可以**在单线程的情况下**对多个fd进行IO操作。
* 它的优势并不在于处理单个连接时效率更高，而是在于能在单线程中同时监听多个fd，避免了大量的系统开销。


## 4.信号驱动IO 
前面的三个模型，我们都需要自己去等待数据到来（不论是阻塞还是轮询）。
信号驱动模型解决了这个问题———它是通过注册信号处理函数`handler()`，在数据到来时内核会发送信号，程序就能在`handler()`中进行数据的读取
* 线程**无需等待或轮询数据的状态，而是可以完成其他任务**，在信号到来时自动处理
* 这是类似于**回调**的概念

## 5.异步IO
上述的模型中，无论在数据到来前是哪种方式，**在读取数据时它们总是阻塞的**；在数据从内核缓冲区被搬移到用户缓冲区的这段时间内，该线程不能做其他事情。
异步IO模型中，我们只需要发起一个读请求（指定好需要缓存数据的位置），就可以继续完成自己的任务了，**内核会在数据读取完成后再通过信号通知程序**。

### 五种IO模型的对比
![avatar](./imgs/IO.jpg)

---

# `select()`, `poll()`, `epoll()`的区别

---
# Linux常用系统相关指令
## 查看CPU和内存使用
* **top** 查看CPU
* **free** 查看内存使用情况

##  **进程相关**
* **ps -l** 查看当前bash下的进程
* **ps aux** 查看所有进程
* **pstree [PID]** 查看PID的进程关系
* **kill -[SIG] [PID]** 向PID进程发送SIG

* 3.